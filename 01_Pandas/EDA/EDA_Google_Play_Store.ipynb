{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Google playstore Data**\n",
    "**Complete Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Dataset\n",
    "\n",
    ">- **`Description`**\\\n",
    "> The Data Set was downloaded from Kaggle, from the following [link](https://www.kaggle.com/datasets/lava18/google-play-store-apps/)\n",
    "\n",
    "- `Context`\n",
    "While many public datasets (on Kaggle and the like) provide Apple App Store data, there are not many counterpart datasets available for Google Play Store apps anywhere on the web. On digging deeper, I found out that iTunes App Store page deploys a nicely indexed appendix-like structure to allow for simple and easy web scraping. On the other hand, Google Play Store uses sophisticated modern-day techniques (like dynamic page load) using JQuery making scraping more challenging.\n",
    "\n",
    "- `Content`\n",
    "Each app (row) has values for catergory, rating, size, and more.\n",
    "\n",
    "- `Acknowledgements`\n",
    "This information is scraped from the Google Play Store. This app information would not be available without it.\n",
    "\n",
    "- `Inspiration`\n",
    "The Play Store apps data has enormous potential to drive app-making businesses to success. Actionable insights can be drawn for developers to work on and capture the Android market!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Data Loading and exploration and cleaning**\n",
    " ↪ Load the csv file with the pandas\n",
    " \n",
    " ↪ creating the dataframe and understanding the data present in the dataset using pandas\n",
    " \n",
    " ↪ Dealing with the missing data, outliers and the incorrect records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('googleplaystore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Some the output of notebook does not present the complete output, therefore we can increase the limit of columns view and row view by using these commands: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # this is to display all the columns in the dataframe\n",
    "pd.set_option('display.max_rows', None) # this is to display all the rows in the dataframe\n",
    "# hide all warnings runtime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's see the exact column names which can be easily copied later on from Google Playstore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's see the exact column names which can be easily copied later on from Google Playstore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not enough, let's have a look on the columns and their data types using detailed info function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Observations**\n",
    "---\n",
    "1. There are 10841 rows and 13 columns in the dataset\n",
    "2. The columns are of different data types\n",
    "3. The columns in the datasets are:\n",
    "   - `'App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type',\n",
    "       'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver',\n",
    "       'Android Ver'`\n",
    "4. There are some missing values in the dataset which we will read in details and deal later on in the notebook.\n",
    "5. There are some columns which are of object data type but they should be of numeric data type, we will convert them later on in the notebook.\n",
    "   - `'Size', 'Installs', 'Price'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "---\n",
    "- We have only 2 columns as numeric data type, rest all are object data type (according to python), but we can see that `'Size', 'Installs', 'Price'` are also numeric, we must convert them to numeric data type in data wrangling process.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's clean the `Size` column first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First check null values\n",
    "data['Size'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Unique Values \n",
    "data['Size'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  There are several uniques values in the `Size` column, we have to first make the unit into one common unit from M and K to bytes, and then remove the `M` and `K` from the values and convert them into numeric data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the values in size column which has 'M' in it\n",
    "data['Size'].loc[data['Size'].str.contains('M')].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the values in size column which has 'k' in it\n",
    "data['Size'].loc[data['Size'].str.contains('k')].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the values in size column which has 'Varies with device' in it\n",
    "data['Size'].loc[data['Size'].str.contains('Varies with device')].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Values in Size column\n",
    "data['Size'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have `8830` values in `M` units\n",
    "- We have `316` values in `k` units\n",
    "- We have `1695` value in `Varies with device` \n",
    "\n",
    "> Let's convert the `M` and `K` units into bytes and then remove the `M` and `K` from the values and convert them into numeric data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will convert the size column to numeric\n",
    "def convert_size(size):\n",
    "    if isinstance(size, str):\n",
    "        if 'k' in size:\n",
    "            return float(size.replace('k', '')) * 1024\n",
    "        elif 'M' in size:\n",
    "            return float(size.replace('M', '')) * 1024 * 1024\n",
    "        elif 'Varies with device' in size:\n",
    "            return np.nan\n",
    "    return size\n",
    "\n",
    "data['Size'] = data['Size'].apply(convert_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column name 'Size' to 'Size_in_bytes'\n",
    "data.rename(columns={'Size': 'Size_in_bytes'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we have converted every value into bytes and removed the `M` and `K` from the values and converted them into numeric data type.\n",
    "- 'Varies with device' was a string value, therefore we intentionally converted them into null values, which we can fill later on according to our needs.\n",
    "\n",
    "---\n",
    "- Let's have a look on the `Installs` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique values in size column\n",
    "data['Installs'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a values counts\n",
    "data['Installs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how many values has '+' in it\n",
    "data['Installs'].loc[data['Installs'].str.contains('\\+')].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total values in Installs column\n",
    "data['Installs'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The total values in the `Installs` column are `10841` and there are no null values in the column.\n",
    "- However, one value 0 has no plus sign\n",
    "\n",
    "- Let's remove the plus sign `+` and `,` from the values and convert them into numeric data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the plus sign from install column and convert it to numeric\n",
    "data['Installs'] = data['Installs'].apply(lambda x: x.replace('+', '') if '+' in str(x) else x)\n",
    "# also remove the commas from the install column\n",
    "data['Installs'] = data['Installs'].apply(lambda x: x.replace(',', '') if ',' in str(x) else x)\n",
    "# convert the install column to numeric (integers because this is the number of installs/count)\n",
    "data['Installs'] = data['Installs'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's verify if the dtypes has been changes and the `+` and `,` sign has been removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Installs'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Installs'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can generate a new columns based on the installation values, which will be helpful in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a new column called 'Installs_category' which will have the category of the installs\n",
    "bins = [-1, 0, 10, 1000, 10000, 100000, 1000000, 10000000, 10000000000]\n",
    "labels=['no', 'Very low', 'Low', 'Moderate', 'More than moderate', 'High', 'Very High', 'Top Notch']\n",
    "data['Installs_category'] = pd.cut(data['Installs'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Installs_category'].value_counts() # check the value counts of the new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's have a look on the `Price` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique values in the 'Price' column\n",
    "data['Price'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to confirm if the values in the `Price` column are only with $ sign or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the values having $ in the 'Price' column\n",
    "data['Price'].loc[data['Price'].str.contains('\\$')].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can confirm that the only currency used is `$` in the `Price` column or 0 value, as `800+10041=10841 Total values`\n",
    "- The only problem is $ sign let's remove it and convert the column into numeric data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the dollar sign from the price column and convert it to numeric\n",
    "data['Price'] = data['Price'].apply(lambda x: x.replace('$', '') if '$' in str(x) else x)\n",
    "# convert the price column to numeric (float because this is the price)\n",
    "data['Price'] = data['Price'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using f string to print the min, max and average price of the apps\n",
    "print(f\"Min price is: {data['Price'].min()} $\")\n",
    "print(f\"Max price is: {data['Price'].max()} $\")\n",
    "print(f\"Average price is: {data['Price'].mean()} $\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1. Descriptive Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "---\n",
    "- Now, we have only 6 columns as numeric data type.\n",
    "- We can observe their descriptive statistics. and make tons of observations as per our hypotheses.\n",
    "- We can see that the `Rating` column has a minimum value of `1` and a maximum value of `5`, which is the range of rating, and the mean is `4.19` which is a good rating. On an average people give this rating.\n",
    "- We can see that the `Reviews` column has a minimum value of `0` and a maximum value of `78,158,306` 78+ Millions, which is the range of reviews, and the mean is `444,111.93` which is a good number of reviews. On an average people give this number of reviews to the apps. But it does not make sense to us, as we have different categories of apps.\n",
    "- Similarly, we can observe the other columns as well.\n",
    "\n",
    "Therefore, the most important thing is to classify as app based on the correlation matrix and then observe the descriptive statistics of the app category and number of installs, reviews, ratings, etc.\n",
    "\n",
    "But even before that we have to think about the missing values in the dataset.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2. Dealing with the missing values**\n",
    "Dealing with the missing values is one of the most important part of the data wrangling process, we must deal with the missing values in order to get the correct insights from the data.\n",
    "\n",
    "## Where to Learn more about Missing Values?\n",
    "In the following blog [Missing Values k Rolay](https://codanics.com/missing-values-k-rolay/) you will understand how missing values can change your output if you ignore them and how to deal with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets looks have a missing values in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.isnull().sum() / len(data) * 100).sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets plots a missing values in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Lets Plot missing value according to percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make figure size\n",
    "plt.figure(figsize=(16, 6))\n",
    "# plot the null values by their percentage in each column\n",
    "missing_percentage = data.isnull().sum()/len(data)*100\n",
    "missing_percentage.plot(kind='bar')\n",
    "# add the labels\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Percentage of Missing Values in each Column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "---\n",
    "- We have 1695 missing values in the `'Size_in_bytes'` and `'Size_in_Mb'` columns, which is 15.6% of the total values in the column.\n",
    "- We have 1474 missing values in the `'Rating'` column, which is 13.6% of the total values in the column.\n",
    "- We have 8 missing value in the `'Current Ver'` column, which is 0.07% of the total values in the column.\n",
    "- We have 2 missing values in the `'Android Ver'` column, which is 0.01% of the total values in the column.\n",
    "- We have only 1 missing value in `Category`, `Type` and `Genres` columns, which is 0.009% of the total values in the column.\n",
    "\n",
    "### **2.3. Dealing with the missing values**\n",
    "- We can not impute the `Rating` column as is is directly linked with the installation column. To test this Hypothesis we need to plot the `Rating` column with the `Installs` and `Size` columns and statistically test it using `pearson correlation test`.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets Start the process of corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a correlation matrix of numeric columns\n",
    "plt.figure(figsize=(16, 10)) # make figure size  \n",
    "numeric_cols = ['Rating', 'Reviews', 'Size_in_bytes', 'Installs', 'Price'] # make a list of numeric columns\n",
    "sns.heatmap(data[numeric_cols].corr(), annot=True) # plot the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[numeric_cols].corr() # this will show the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "data_clean = data.dropna()\n",
    "\n",
    "# calculate Pearson's R between Rating and Installs\n",
    "pearson_r, _ = stats.pearsonr(data_clean['Reviews'], data_clean['Installs'])\n",
    "print(f\"Pearson's R between Reviews and Installs: {pearson_r:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before going ahead, let's remove the rows with missing values in the `Current Ver`, `Android Ver`, `Category`, `Type` and `Genres` columns, as they are very less in number and will not affect our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length before removing null values\n",
    "print(f\"Length of the dataframe after removing null values: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['Current Ver', 'Android Ver', 'Category', 'Type', 'Genres'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length after removing null values\n",
    "print(f\"Length of the dataframe after removing null values: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have removed `12` rows having null values in the `Current Ver`, `Android Ver`, `Category`, `Type` and `Genres` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the null values again\n",
    "data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Observations**\n",
    "- Only `Rating` and `Size_in_bytes` or `Size_in_Mb` columns are left with missing values.\n",
    "  - We know that we have to be carefull while deadling with `Rating` column, as it is directly linked with the `Installs` column.\n",
    "  - In Size columns we already know about `Varies with device` values, which we have converted into null values, we do not need to impute at the moment, as every app has different size and nobody can predict that as nearly as possible.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use groupby function to find the trend of Rating in each Installs_category\n",
    "data.groupby('Installs_category')['Rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Rating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Installs_category'].loc[data['Rating'].isnull()].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets plot this and have a Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxplot of Rating in each Installs_category\n",
    "plt.figure(figsize=(16, 6)) # make figure size\n",
    "sns.boxplot(x='Installs_category', y='Rating', hue='Installs_category', data=data) # plot the boxplot\n",
    "# add the text of number of null values in each category\n",
    "plt.text(0, 3.5, 'Null values: 14')\n",
    "plt.text(1, 3.5, 'Null values: 874')\n",
    "plt.text(2, 3.5, 'Null values: 86')\n",
    "plt.text(3, 3.5, 'Null values: 31')\n",
    "plt.text(4, 3.5, 'Null values: 3')\n",
    "plt.text(5, 3.5, 'Null values: 0')\n",
    "plt.text(6, 3.5, 'Null values: 0')\n",
    "plt.text(7, 3.5, 'Null values: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Installs_category'].loc[data['Reviews'].isnull()].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are no null value in Reiview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the same plots for Reviews column as well\n",
    "plt.figure(figsize=(16, 6)) # make figure size\n",
    "sns.boxplot(x='Installs_category', y= 'Reviews', data=data) # plot the boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We also draw the scatter plot of the `Rating` and `Review` columns with the `Installs` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a scatter plot between Rating, Reviews and Installs\n",
    "plt.figure(figsize=(16, 6)) # make figure size\n",
    "sns.scatterplot(x='Rating', y='Reviews', hue='Installs_category', data=data) # plot the scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reviews and installs in a scatter plot\n",
    "plt.figure(figsize=(16, 6)) # make figure size\n",
    "sns.scatterplot(x='Reviews', y='Installs', data=data) # plot the scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Observation**\n",
    "-We can see that most of the null values from `Rating` column are no - Moderate Installation apps, which make sense that if the app has less installations, it has less Rating and review.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. **Duplicates**\n",
    "\n",
    "* Removing duplicates is one of the most important part of the data wrangling process, we must remove the duplicates in order to get the correct insights from the data.\n",
    "* If you do not remove duplicates from a dataset, it can lead to incorrect insights and analysis. \n",
    "* Duplicates can skew statistical measures such as mean, median, and standard deviation, and can also lead to over-representation of certain data points. \n",
    "* It is important to remove duplicates to ensure the accuracy and reliability of your data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* let's check for number of duplicates in each column using a for loop and printing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    print(f\"Number of Dulicates in {col} columns are {data[col].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This means that the only better way to find duplicates is to check for whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Duplicated in whole data is {data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find and watch all duplicates if they are real!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find exact duplicates and print them\n",
    "data[data['App'].duplicated(keep=False)].sort_values(by='App')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removes all Duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows and columns after removing duplicates\n",
    "print(f\"Number of rows after removing duplicates: {data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we have removed 483 duplicates from the dataset. and have 10346 rows left.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
